{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8a7b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy, F1Score\n",
    "\n",
    "import pytorch_optimizer as optim1\n",
    "import optuna\n",
    "\n",
    "pl.seed_everything(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f65c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class KaggleTestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Path ke direktori berisi semua gambar test.\n",
    "            transform (callable, optional): Transformasi yang akan diterapkan pada gambar.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Mengambil satu item data.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Indeks dari item.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (image, image_name) di mana image_name adalah nama file.\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        image_name = self.image_files[idx]\n",
    "        return image, image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e664d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomPerspective(),\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "            transforms.ColorJitter(),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = 'dataset_split'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=f'{data_dir}/train_final', transform=train)\n",
    "val_dataset = datasets.ImageFolder(root=f'{data_dir}/validation', transform=val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58622c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data test: 1\n"
     ]
    }
   ],
   "source": [
    "data_test_dir = 'dsc-logika-ui-2025'\n",
    "\n",
    "test_dataset = KaggleTestDataset(root_dir=data_test_dir, transform=val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "print(f'Jumlah data test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ebf143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, target = next(iter(train_loader))\n",
    "feature.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79885754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\n",
    "label2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33863dd",
   "metadata": {},
   "source": [
    "Arsitektur dan config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "679c7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_feature, out_feature, padding=1, stride=1,\n",
    "             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n",
    "             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n",
    "    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n",
    "    if activation == \"relu\":\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == \"leakyrelu\":\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == \"sigmoid\":\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == 'mish': layers.append(nn.Mish())\n",
    "    elif activation == \"tanh\":\n",
    "        layers.append(nn.Tanh())\n",
    "    if pool:\n",
    "        if maxpool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "        else:\n",
    "            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "    else:\n",
    "        layers.append(nn.Identity())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n",
    "    layers = [nn.Linear(in_features, out_features)]\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm1d(out_features))\n",
    "    if activation == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == 'sigmoid':\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == 'tanh':\n",
    "        layers.append(nn.Tanh())\n",
    "    elif activation == 'leakyrelu':\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == 'mish': layers.append(nn.Mish())\n",
    "    elif activation == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif activation == 'elu':\n",
    "        layers.append(nn.ELU())\n",
    "    elif activation == 'selu':\n",
    "        layers.append(nn.SELU())\n",
    "    elif activation == 'lsoftmax':\n",
    "        layers.append(nn.LogSoftmax(dim=1))\n",
    "    if dropout > 0.0:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27a449c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(LightningModule):\n",
    "    def __init__(self, dropout) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv_block(3, 8),\n",
    "            conv_block(8, 16),\n",
    "            conv_block(16, 32),\n",
    "            conv_block(32, 64),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            linear_block(64*14*14, 512, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(512, 256, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(256, 128, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(128, 64, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(64, 32, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(32, 5, activation=None)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.fc(self.conv(X))\n",
    "        \n",
    "class PL(LightningModule):\n",
    "    def __init__(self, model, learning_rate) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        X, labels = batch\n",
    "        outputs = self(X) \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        macrof1 = self.macroF1(outputs, labels)\n",
    "        return loss, macrof1\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_macrof1', macroF1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def backward(self, loss, *args, **kwargs):\n",
    "        loss.backward(create_graph=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim1.Lion(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        if isinstance(batch, list) or isinstance(batch, tuple):\n",
    "            X, _ = batch\n",
    "        else:\n",
    "            X = batch\n",
    "        logits = self(X)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c19ac7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator_type = 'gpu'\n",
    "    devices_to_use = 1\n",
    "else:\n",
    "    accelerator_type = 'cpu'\n",
    "    devices_to_use = 'auto'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_macrof1',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='logikaui-{epoch:02d}-{val_macrof1:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    ")\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback],\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"simple_model_experiment\"),\n",
    "    accelerator=accelerator_type,\n",
    "    devices=devices_to_use,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad56595",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a5c98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PL(CNN(dropout=0.2), learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d142303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | CNN               | 6.6 M  | train\n",
      "1 | criterion | CrossEntropyLoss  | 0      | train\n",
      "2 | macroF1   | MulticlassF1Score | 0      | train\n",
      "--------------------------------------------------------\n",
      "6.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 M     Total params\n",
      "26.497    Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248f4a51b05d4189b400858cba7e6fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6ed718a722428392fd98804e6d5293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975527daf92d4d26b1e7e38f1ac66eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c69bd2e4ecf4d279656b91daa515cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc99f2527064a14a5be4e28144b41a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "trainer1.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ba917",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer1.validate(model, test_loader, ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f001afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmsdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
