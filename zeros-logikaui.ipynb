{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":115446,"databundleVersionId":13809662,"sourceType":"competition"},{"sourceId":13156543,"sourceType":"datasetVersion","datasetId":8336088}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c8a7b00d","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torchvision import models\nimport torch._dynamo\ntorch._dynamo.config.suppress_errors = True\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom torchmetrics.classification import MulticlassAccuracy, F1Score\n!uv pip install pytorch_optimizer\nimport pytorch_optimizer as optim1\nimport optuna\n\npl.seed_everything(42)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-09-24T16:48:52.960332Z","iopub.execute_input":"2025-09-24T16:48:52.961077Z","iopub.status.idle":"2025-09-24T16:48:58.712885Z","shell.execute_reply.started":"2025-09-24T16:48:52.961053Z","shell.execute_reply":"2025-09-24T16:48:58.712020Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 128ms\u001b[0m\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"63f65c46","cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\n\nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Path ke direktori berisi semua gambar test.\n            transform (callable, optional): Transformasi yang akan diterapkan pada gambar.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n        self.image_files = sorted([\n        f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f)) and os.path.splitext(f)[1].lower() in allowed_extensions\n        ])\n\n    def __len__(self):\n        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Mengambil satu item data.\n\n        Args:\n            idx (int): Indeks dari item.\n        \n        Returns:\n            tuple: (image, image_name) di mana image_name adalah nama file.\n        \"\"\"\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        image_name = self.image_files[idx]\n        return image, image_name","metadata":{"execution":{"iopub.status.busy":"2025-09-24T16:48:58.714413Z","iopub.execute_input":"2025-09-24T16:48:58.715054Z","iopub.status.idle":"2025-09-24T16:48:58.722284Z","shell.execute_reply.started":"2025-09-24T16:48:58.715030Z","shell.execute_reply":"2025-09-24T16:48:58.721586Z"},"trusted":true},"outputs":[],"execution_count":2},{"id":"8be3aa77-d154-4a0c-a364-693526f20b23","cell_type":"code","source":"weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\nauto_transforms = weights.transforms()\nprint(auto_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:48:58.723091Z","iopub.execute_input":"2025-09-24T16:48:58.723647Z","iopub.status.idle":"2025-09-24T16:48:58.745385Z","shell.execute_reply.started":"2025-09-24T16:48:58.723624Z","shell.execute_reply":"2025-09-24T16:48:58.744742Z"}},"outputs":[{"name":"stdout","text":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BICUBIC\n)\n","output_type":"stream"}],"execution_count":3},{"id":"7e664d77","cell_type":"code","source":"train= transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            transforms.RandomPerspective(),\n            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n            transforms.ColorJitter(),\n            transforms.Grayscale(num_output_channels=3),\n            auto_transforms\n])\nval = transforms.Compose([\n        auto_transforms\n])\ndata_dir = '/kaggle/input/logika/Train/'\n\ntrain_dataset = datasets.ImageFolder(root=f'{data_dir}Train', transform=train)\nlabels = train_dataset.targets\nclass_counts = torch.bincount(torch.tensor(labels))\nprint(f\"Pemetaan kelas: {train_dataset.class_to_idx}\")\nprint(f\"Jumlah sampel per kelas: {class_counts}\")\nclass_weights = 1.0 / class_counts.float()\nprint(f\"Bobot untuk setiap kelas: {class_weights}\")\nweights_per_sample = class_weights[labels]\nprint(f\"Panjang bobot per sampel: {len(weights_per_sample)}\")\nprint(\"Contoh 5 bobot pertama:\", weights_per_sample[:5])\n\nsampler = WeightedRandomSampler(weights_per_sample, num_samples=len(weights_per_sample), replacement=True)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, sampler=sampler)\nprint(f'Jumlah data test: {len(train_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-24T16:48:58.746865Z","iopub.execute_input":"2025-09-24T16:48:58.747128Z","iopub.status.idle":"2025-09-24T16:48:59.544597Z","shell.execute_reply.started":"2025-09-24T16:48:58.747087Z","shell.execute_reply":"2025-09-24T16:48:59.543921Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Pemetaan kelas: {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nJumlah sampel per kelas: tensor([776,  95,  69, 249, 563])\nBobot untuk setiap kelas: tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])\nPanjang bobot per sampel: 1752\nContoh 5 bobot pertama: tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0013])\nJumlah data test: 1752\n","output_type":"stream"}],"execution_count":4},{"id":"b58622c1","cell_type":"code","source":"data_test_dir = '/kaggle/input/logika/Test/Test'\n\ntest_dataset = TestDataset(root_dir=data_test_dir, transform=val)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\nprint(f'Jumlah data test: {len(test_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-24T16:48:59.545291Z","iopub.execute_input":"2025-09-24T16:48:59.545543Z","iopub.status.idle":"2025-09-24T16:48:59.758182Z","shell.execute_reply.started":"2025-09-24T16:48:59.545525Z","shell.execute_reply":"2025-09-24T16:48:59.757549Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Jumlah data test: 444\n","output_type":"stream"}],"execution_count":5},{"id":"b9a122c5-e7b2-42ed-aed7-9a77b1230c57","cell_type":"code","source":"feature = next(iter(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:48:59.758902Z","iopub.execute_input":"2025-09-24T16:48:59.759131Z"}},"outputs":[],"execution_count":null},{"id":"e5ebf143","cell_type":"code","source":"# for i in feature:\n#     print(f'{i}: {len(i)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"79885754","cell_type":"code","source":"label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\nlabel2cat","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c33863dd","cell_type":"markdown","source":"## Arsitektur dan config","metadata":{}},{"id":"679c7a9f","cell_type":"code","source":"def conv_block(in_feature, out_feature, padding=1, stride=1,\n             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n    if activation == \"relu\":\n        layers.append(nn.ReLU())\n    elif activation == \"leakyrelu\":\n        layers.append(nn.LeakyReLU())\n    elif activation == \"sigmoid\":\n        layers.append(nn.Sigmoid())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == \"tanh\":\n        layers.append(nn.Tanh())\n    if pool:\n        if maxpool:\n            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n        else:\n            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n    else:\n        layers.append(nn.Identity())\n    return nn.Sequential(*layers)\n\n\ndef linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n    layers = [nn.Linear(in_features, out_features)]\n    if batch_norm:\n        layers.append(nn.BatchNorm1d(out_features))\n    if activation == 'relu':\n        layers.append(nn.ReLU())\n    elif activation == 'sigmoid':\n        layers.append(nn.Sigmoid())\n    elif activation == 'tanh':\n        layers.append(nn.Tanh())\n    elif activation == 'leakyrelu':\n        layers.append(nn.LeakyReLU())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == 'softmax':\n        layers.append(nn.Softmax(dim=1))\n    elif activation == 'elu':\n        layers.append(nn.ELU())\n    elif activation == 'selu':\n        layers.append(nn.SELU())\n    elif activation == 'lsoftmax':\n        layers.append(nn.LogSoftmax(dim=1))\n    if dropout > 0.0:\n        layers.append(nn.Dropout(dropout))\n    return nn.Sequential(*layers)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"27a449c0","cell_type":"code","source":"class EfficientNet(nn.Module):\n    def __init__(self, dropout=0.0, freeze=True):\n        super().__init__()\n        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        self.model = models.efficientnet_b0(weights=weights)\n        if freeze:\n            for param in self.model.parameters():\n                param.requires_grad = False\n        num_in_features = self.model.classifier[1].in_features\n        self.model.classifier = nn.Sequential(\n            linear_block(num_in_features, 256, activation='mish', dropout=dropout, batch_norm=True),\n            linear_block(256, 128, activation='mish', dropout=dropout, batch_norm=True),\n            linear_block(128, 5, activation=None)\n        )\n    def forward(self, X):\n        return self.model(X)\n        \nclass PL(LightningModule):\n    def __init__(self, model, learning_rate, class_weights) -> None:\n        super().__init__()\n        self.model = model\n        self.learning_rate = learning_rate\n        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n    \n    def forward(self, X):\n        return self.model(X)\n    \n    def _common_step(self, batch, batch_idx):\n        X, labels = batch\n        outputs = self(X) \n        loss = self.criterion(outputs, labels)\n        macrof1 = self.macroF1(outputs, labels)\n        return loss, macrof1\n\n    def training_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_macrof1', macroF1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def backward(self, loss, *args, **kwargs):\n        loss.backward(create_graph=True)\n\n    def configure_optimizers(self):\n        optimizer = optim1.Lion(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        \"\"\"\n        Langkah prediksi untuk satu batch data test.\n        \"\"\"\n        images, image_names = batch\n        outputs = self.forward(images)\n        _, predicted_labels = torch.max(outputs, 1)\n        return {\"image_names\": image_names, \"preds\": predicted_labels}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c19ac7d8","cell_type":"code","source":"if torch.cuda.is_available():\n    accelerator_type = 'gpu'\n    devices_to_use = 1\nelse:\n    accelerator_type = 'cpu'\n    devices_to_use = 'auto'\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='train_macrof1',\n    dirpath='checkpoints/',\n    filename='logikaui-{epoch:02d}-{train_macrof1:.2f}',\n    save_top_k=1,\n    mode='max'\n)\nearly_stopping = EarlyStopping(\n    monitor='train_loss',\n    patience=10,\n    mode='min',\n)\nlr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n\ntrainer1 = pl.Trainer(\n    max_epochs=300,\n    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback],\n    logger=TensorBoardLogger(\"tb_logs\", name=\"simple_model_experiment\"),\n    accelerator=accelerator_type,\n    devices=devices_to_use,\n    log_every_n_steps=10,\n    deterministic=True,\n    precision='16-mixed'\n\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1ad56595","cell_type":"markdown","source":"## Train","metadata":{}},{"id":"c3324805-104f-4284-8da7-7cc954a207bd","cell_type":"code","source":"class_weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9a5c98a3","cell_type":"code","source":"model = PL(EfficientNet(dropout=0.1, freeze=True), learning_rate=5e-4, class_weights=class_weights)\n# model = torch.compile(model) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6d142303","cell_type":"code","source":"trainer1.fit(model, train_loader, val_dataloaders=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"738ba917","cell_type":"code","source":"if __name__ == \"__main__\":\n    preds = trainer1.predict(model, test_loader, ckpt_path='best')\n    print(preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4f001afb","cell_type":"code","source":"predictions = []\nfor batch_result in preds:\n    # batch_result adalah dictionary yang kita return dari predict_step\n    image_names = batch_result['image_names']\n    preds = batch_result['preds'].cpu().numpy() # Pindahkan ke CPU\n    \n    for name, label in zip(image_names, preds):\n        predictions.append({\n            'id': name,      # Nama kolom sesuai standar Kaggle\n            'style': label   # Nama kolom sesuai standar Kaggle\n        })\npredictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3da01ac3-565b-4a53-90f7-6730ac16ea1a","cell_type":"code","source":"submission_df = pd.DataFrame(predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4a9f8d91-ee0e-4b98-833c-0615ed20cc7d","cell_type":"code","source":"class_mapping = {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nidx_to_class = {v: k for k, v in class_mapping.items()}\n# Cek tipe data dari kolom 'style'. Kemungkinan besar hasilnya 'object' (string).\nprint(f\"Tipe data kolom 'style': {submission_df['style'].dtype}\")\nsubmission_df['id'] = submission_df['id'].str.split('.').str[0]\n\n# Lihat nilai-nilai unik di dalam kolom tersebut.\n# Perhatikan apakah ada tanda kutip, yang menandakan string.\nprint(f\"Nilai unik di kolom 'style': {submission_df['style'].unique()}\")\nsubmission_df['style'] = submission_df['style'].map(idx_to_class)\nsubmission_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6ced9ca8-ef3c-4aa6-b915-1e4272a0c6fd","cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"57a07a0a-b589-4fb8-b9f3-f78788195eac","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}