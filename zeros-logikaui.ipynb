{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13156543,"sourceType":"datasetVersion","datasetId":8336088},{"sourceId":13182263,"sourceType":"datasetVersion","datasetId":8353851},{"sourceId":13204973,"sourceType":"datasetVersion","datasetId":8356889}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c8a7b00d","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport timm\nfrom torch import nn\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import models\n\nfrom torchvision import models\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, Callback\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom torchmetrics.classification import MulticlassAccuracy, F1Score\n!uv pip install pytorch_optimizer\nimport pytorch_optimizer as optim1\n\n","metadata":{"execution":{"iopub.status.busy":"2025-09-29T10:39:37.124710Z","iopub.execute_input":"2025-09-29T10:39:37.125570Z","iopub.status.idle":"2025-09-29T10:39:44.901842Z","shell.execute_reply.started":"2025-09-29T10:39:37.125541Z","shell.execute_reply":"2025-09-29T10:39:44.900860Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 135ms\u001b[0m\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"1854dab9-291e-4281-9a7c-1739c9672c90","cell_type":"code","source":"pl.seed_everything(42)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:44.903552Z","iopub.execute_input":"2025-09-29T10:39:44.904372Z","iopub.status.idle":"2025-09-29T10:39:44.932637Z","shell.execute_reply.started":"2025-09-29T10:39:44.904345Z","shell.execute_reply":"2025-09-29T10:39:44.932101Z"}},"outputs":[],"execution_count":2},{"id":"63f65c46","cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\n\nclass AlbumentationsImageFolder(ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform=None)  # disable default transform\n        self.albumentations_transform = transform\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        image = self.loader(path)  # default loader (PIL)\n        image = np.array(image)    # PIL → NumPy\n        if self.albumentations_transform:\n            image = self.albumentations_transform(image=image)[\"image\"]\n        return image, label\n\n\nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Path ke direktori berisi semua gambar test.\n            transform (callable, optional): Transformasi Albumentations yang akan diterapkan pada gambar.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n        self.image_files = sorted([\n            f for f in os.listdir(root_dir) \n            if os.path.isfile(os.path.join(root_dir, f)) \n            and os.path.splitext(f)[1].lower() in allowed_extensions\n        ])\n\n    def __len__(self):\n        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Mengambil satu item data.\n\n        Args:\n            idx (int): Indeks dari item.\n        \n        Returns:\n            tuple: (image_tensor, image_name)\n        \"\"\"\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        image = np.array(image)  # PIL → NumPy (H, W, C)\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n\n        image_name = self.image_files[idx]\n        return image, image_name","metadata":{"execution":{"iopub.status.busy":"2025-09-29T10:39:44.933420Z","iopub.execute_input":"2025-09-29T10:39:44.933623Z","iopub.status.idle":"2025-09-29T10:39:44.942774Z","shell.execute_reply.started":"2025-09-29T10:39:44.933607Z","shell.execute_reply":"2025-09-29T10:39:44.942099Z"},"trusted":true},"outputs":[],"execution_count":3},{"id":"8be3aa77-d154-4a0c-a364-693526f20b23","cell_type":"code","source":"weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\nauto_transforms = weights.transforms()\nprint(auto_transforms)","metadata":{"execution":{"iopub.status.busy":"2025-09-29T10:39:44.944147Z","iopub.execute_input":"2025-09-29T10:39:44.944346Z","iopub.status.idle":"2025-09-29T10:39:44.962548Z","shell.execute_reply.started":"2025-09-29T10:39:44.944330Z","shell.execute_reply":"2025-09-29T10:39:44.961857Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BICUBIC\n)\n","output_type":"stream"}],"execution_count":4},{"id":"7e664d77","cell_type":"code","source":"train_transform = A.Compose([\n    A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),\n    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, min_holes=1, fill_value=0, p=0.5),\n    A.Normalize(mean=(0.5, 0.5, 0.5),std=(0.5, 0.5, 0.5)),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.5, 0.5, 0.5),std=(0.5, 0.5, 0.5)),\n    ToTensorV2()\n])\n\nbs = 32\ndata_train = '/kaggle/input/logika/Train/Train'\n\ntrain_dataset = AlbumentationsImageFolder(root=data_train, transform=train_transform)\nlabels = train_dataset.targets\nclass_counts = torch.bincount(torch.tensor(labels))\nprint(f\"Pemetaan kelas: {train_dataset.class_to_idx}\")\nprint(f\"Jumlah sampel per kelas: {class_counts}\")\nclass_weights = 1.0 / class_counts.float()\nprint(f\"Bobot untuk setiap kelas: {class_weights}\")\nweights_per_sample = class_weights[labels]\nprint(f\"Panjang bobot per sampel: {len(weights_per_sample)}\")\nprint(\"Contoh 5 bobot pertama:\", weights_per_sample[:5])\n\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(train_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-29T10:39:44.963266Z","iopub.execute_input":"2025-09-29T10:39:44.963990Z","iopub.status.idle":"2025-09-29T10:39:45.639884Z","shell.execute_reply.started":"2025-09-29T10:39:44.963962Z","shell.execute_reply":"2025-09-29T10:39:45.638959Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Pemetaan kelas: {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nJumlah sampel per kelas: tensor([776,  95,  69, 249, 563])\nBobot untuk setiap kelas: tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])\nPanjang bobot per sampel: 1752\nContoh 5 bobot pertama: tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0013])\nJumlah data test: 1752\n","output_type":"stream"}],"execution_count":5},{"id":"b58622c1","cell_type":"code","source":"data_test_dir = '/kaggle/input/logika/Test/Test'\n\ntest_dataset = TestDataset(root_dir=data_test_dir, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(test_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-29T10:39:45.640884Z","iopub.execute_input":"2025-09-29T10:39:45.641193Z","iopub.status.idle":"2025-09-29T10:39:45.866058Z","shell.execute_reply.started":"2025-09-29T10:39:45.641166Z","shell.execute_reply":"2025-09-29T10:39:45.865258Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Jumlah data test: 444\n","output_type":"stream"}],"execution_count":6},{"id":"79885754","cell_type":"code","source":"label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\nlabel2cat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.866927Z","iopub.execute_input":"2025-09-29T10:39:45.867173Z","iopub.status.idle":"2025-09-29T10:39:45.872902Z","shell.execute_reply.started":"2025-09-29T10:39:45.867156Z","shell.execute_reply":"2025-09-29T10:39:45.872317Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}"},"metadata":{}}],"execution_count":7},{"id":"c33863dd","cell_type":"markdown","source":"## Arsitektur dan config","metadata":{}},{"id":"679c7a9f","cell_type":"code","source":"def conv_block(in_feature, out_feature, padding=1, stride=1,\n             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n    if activation == \"relu\":\n        layers.append(nn.ReLU())\n    elif activation == \"leakyrelu\":\n        layers.append(nn.LeakyReLU())\n    elif activation == \"sigmoid\":\n        layers.append(nn.Sigmoid())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == \"tanh\":\n        layers.append(nn.Tanh())\n    if pool:\n        if maxpool:\n            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n        else:\n            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n    else:\n        layers.append(nn.Identity())\n    return nn.Sequential(*layers)\n\n\ndef linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n    layers = [nn.Linear(in_features, out_features)]\n    if batch_norm:\n        layers.append(nn.BatchNorm1d(out_features))\n    if activation == 'relu':\n        layers.append(nn.ReLU())\n    elif activation == 'sigmoid':\n        layers.append(nn.Sigmoid())\n    elif activation == 'tanh':\n        layers.append(nn.Tanh())\n    elif activation == 'leakyrelu':\n        layers.append(nn.LeakyReLU())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == 'gelu': layers.append(nn.GELU())\n    elif activation == 'softmax':\n        layers.append(nn.Softmax(dim=1))\n    elif activation == 'elu':\n        layers.append(nn.ELU())\n    elif activation == 'selu':\n        layers.append(nn.SELU())\n    elif activation == 'lsoftmax':\n        layers.append(nn.LogSoftmax(dim=1))\n    if dropout > 0.0:\n        layers.append(nn.Dropout(dropout))\n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.873565Z","iopub.execute_input":"2025-09-29T10:39:45.873850Z","iopub.status.idle":"2025-09-29T10:39:45.887924Z","shell.execute_reply.started":"2025-09-29T10:39:45.873826Z","shell.execute_reply":"2025-09-29T10:39:45.887272Z"}},"outputs":[],"execution_count":8},{"id":"27a449c0","cell_type":"code","source":"class Backbone(nn.Module):\n    def __init__(self, backbone=\"efficientnet_b0\", dropout=0.0, freeze=True):\n        super().__init__()\n        self.backbone_name = backbone\n\n        if backbone == \"efficientnet_b0\":\n            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n            self.backbone = models.efficientnet_b0(weights=weights).features\n            feature_dim = 1280\n            self.needs_pooling = True\n\n        elif backbone == \"efficientformer_l1\":\n            self.backbone = timm.create_model(\"efficientformer_l1\", pretrained=True, num_classes=0)\n            feature_dim = 448\n            self.needs_pooling = False\n\n        else:\n            raise ValueError(f\"Backbone {backbone} tidak didukung\")\n\n        if freeze:\n            for param in self.backbone.parameters():\n                param.requires_grad = False\n        else:\n            print(\"param backbone unfreeze\")\n            for param in self.backbone.parameters():\n                param.requires_grad = True\n\n        self.classifier = nn.Sequential(\n            linear_block(feature_dim, 128, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(128, 64, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(64, 5, activation=None)\n        )\n\n    def forward(self, X):\n        X = self.backbone(X)\n        if self.needs_pooling: \n            X = X.mean([2, 3])\n        return self.classifier(X)\n        \nclass PL(LightningModule):\n    def __init__(self, model, class_weights, learning_rate=1e-3) -> None:\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = model\n        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n    \n    def forward(self, X):\n        return self.model(X)\n    \n    def _common_step(self, batch, batch_idx):\n        X, labels = batch\n        outputs = self(X) \n        loss = self.criterion(outputs, labels)\n        macrof1 = self.macroF1(outputs, labels)\n        return loss, macrof1\n\n    def training_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_macrof1', macroF1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def configure_optimizers(self):\n        backbone_params = [p for p in self.model.backbone.parameters() if p.requires_grad]\n        head_params = list(self.model.classifier.parameters())\n    \n        optimizer = optim.AdamW([\n            {\"params\": backbone_params, \"lr\": 3e-5},   \n            {\"params\": head_params, \"lr\": self.hparams.learning_rate},  \n        ], weight_decay=1e-4)\n    \n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=5,      \n            T_mult=1,   \n            eta_min=1e-5 \n        )\n\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        \"\"\"\n        Langkah prediksi untuk satu batch data test.\n        \"\"\"\n        images, image_names = batch\n        outputs = self.forward(images)\n        _, predicted_labels = torch.max(outputs, 1)\n        return {\"image_names\": image_names, \"preds\": predicted_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.888745Z","iopub.execute_input":"2025-09-29T10:39:45.889425Z","iopub.status.idle":"2025-09-29T10:39:45.908490Z","shell.execute_reply.started":"2025-09-29T10:39:45.889407Z","shell.execute_reply":"2025-09-29T10:39:45.907770Z"}},"outputs":[],"execution_count":9},{"id":"2564e101","cell_type":"code","source":"from pytorch_lightning.callbacks import Callback\n\nclass FineTuningCallback(Callback):\n    def __init__(self, unfreeze_schedule, base_backbone_lr=5e-5, head_lr=1e-4, warmup_epochs=10):\n        \"\"\"\n        unfreeze_schedule: dict {epoch: fraction_to_unfreeze}\n            Contoh {1: 0.3, 5: 0.6, 10: 1.0}\n        base_backbone_lr: LR maksimum backbone\n        head_lr: LR classifier head\n        warmup_epochs: jumlah epoch untuk naik linear dari 0 → base_backbone_lr\n        \"\"\"\n        super().__init__()\n        self.unfreeze_schedule = unfreeze_schedule\n        self.base_backbone_lr = base_backbone_lr\n        self.head_lr = head_lr\n        self.warmup_epochs = warmup_epochs\n\n    def on_train_epoch_start(self, trainer, pl_module):\n        current_epoch = trainer.current_epoch\n\n        # Cek apakah ada event unfreeze di epoch ini\n        if current_epoch in self.unfreeze_schedule:\n            fraction = self.unfreeze_schedule[current_epoch]\n            backbone_layers = list(pl_module.model.backbone.children())\n            n_layers = len(backbone_layers)\n            cut_point = int(n_layers * (1 - fraction))\n\n            # Freeze semua dulu\n            for param in pl_module.model.backbone.parameters():\n                param.requires_grad = False\n            # Unfreeze sesuai fraction\n            for layer in backbone_layers[cut_point:]:\n                for param in layer.parameters():\n                    param.requires_grad = True\n\n            print(f\"\\n--- Epoch {current_epoch}: Unfreeze {fraction*100:.0f}% backbone ---\")\n\n        # Hitung LR backbone (linear warmup)\n        progress = min(1.0, (current_epoch + 1) / self.warmup_epochs)\n        backbone_lr = self.base_backbone_lr * progress\n\n        # Update optimizer param groups\n        optimizer = trainer.optimizers[0]\n        defaults = optimizer.defaults\n        param_groups = [\n            {**defaults, \"params\": pl_module.model.backbone.parameters(), \"lr\": backbone_lr},\n            {**defaults, \"params\": pl_module.model.classifier.parameters(), \"lr\": self.head_lr},\n        ]\n        optimizer.param_groups = param_groups\n\n        print(f\"LR backbone={backbone_lr:.2e} (warmup {progress*100:.0f}%), \")\n        print(f\"LR head={self.head_lr:.2e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.910637Z","iopub.execute_input":"2025-09-29T10:39:45.910920Z","iopub.status.idle":"2025-09-29T10:39:45.927811Z","shell.execute_reply.started":"2025-09-29T10:39:45.910905Z","shell.execute_reply":"2025-09-29T10:39:45.927150Z"}},"outputs":[],"execution_count":10},{"id":"dbe4a619-7207-4c4c-9174-0ee67e6a0386","cell_type":"code","source":"import json\nimport yaml\nimport subprocess\nimport shutil\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nKAGGLE_USERNAME = \"dimassp1\"\nDATASET_NAME = \"efficientnet-training-output\"\nDATASET_SLUG = f\"{KAGGLE_USERNAME}/{DATASET_NAME}\"\n\nconfig = {\n    \"architecture\": \"EfficientNet-B0\",\n    \"dropout\": 0.3,\n    \"freeze\": False,\n    \"optimizer\": \"AdamW\",\n    \"optimizer_params\": {\"lr\": 1e-3},\n    \"loss_function\": \"CrossEntropyLoss\",\n    \"metrics\": [\"F1Score_macro\"],\n    \"epochs\": 100,\n    \"batch_size\": bs,\n    \"input_size\": (224, 224),\n    \"num_classes\": 5\n}\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\n\nimport os, shutil, torch, yaml, zipfile\n\ndef save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    best_ckpt_path = checkpoint_callback.best_model_path\n    if best_ckpt_path and os.path.exists(best_ckpt_path):\n        checkpoint_file = os.path.basename(best_ckpt_path)  \n        dst_path = os.path.join(output_dir, checkpoint_file)\n\n        if os.path.abspath(best_ckpt_path) != os.path.abspath(dst_path):\n            shutil.copy(best_ckpt_path, dst_path)\n        else:\n            print(f\"ℹ️ Checkpoint sudah ada di {output_dir}, tidak perlu copy ulang.\")\n\n    else:\n        print(\"⚠️ Best checkpoint belum ada, file .ckpt tidak disalin.\")\n\n    full_state_dict = model.state_dict()\n    backbone_state_dict = {}\n    backbone_keys = [k for k in full_state_dict.keys() if k.startswith(\"features.\")]\n    num_keys_to_save = max(1, int(len(backbone_keys) * backbone_ratio))\n\n    for k in backbone_keys[:num_keys_to_save]:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    head_keys = [k for k in full_state_dict.keys() if k.startswith(\"classifier.\")]\n    for k in head_keys:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    torch.save(backbone_state_dict, os.path.join(output_dir, \"efficientnet_partial_state_dict.pt\"))\n\n    with open(os.path.join(output_dir, \"config.yaml\"), \"w\") as f:\n        yaml.dump(config, f)\n\n    zip_path = os.path.join(output_dir, \"output_dataset.zip\")\n    files_to_zip = [\n        f for f in [\"config.yaml\", \"efficientnet_partial_state_dict.pt\"] \n        if os.path.exists(os.path.join(output_dir, f))\n    ]\n    if best_ckpt_path:\n        files_to_zip.append(os.path.basename(best_ckpt_path))\n\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for f in files_to_zip:\n            file_path = os.path.join(output_dir, f)\n            zipf.write(file_path, arcname=f)\n\n    print(f\"✅ Semua output sudah di-zip: {zip_path}\")\n    return zip_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.928497Z","iopub.execute_input":"2025-09-29T10:39:45.928723Z","iopub.status.idle":"2025-09-29T10:39:45.945088Z","shell.execute_reply.started":"2025-09-29T10:39:45.928708Z","shell.execute_reply":"2025-09-29T10:39:45.944318Z"}},"outputs":[],"execution_count":11},{"id":"2abb4f79-2be0-4d05-aa65-dcdc7252421b","cell_type":"code","source":"schedule = {\n    2000: 0.3,  \n    1000: 0.6,   \n    0: 1.0   \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.945726Z","iopub.execute_input":"2025-09-29T10:39:45.945958Z","iopub.status.idle":"2025-09-29T10:39:45.963294Z","shell.execute_reply.started":"2025-09-29T10:39:45.945941Z","shell.execute_reply":"2025-09-29T10:39:45.962495Z"}},"outputs":[],"execution_count":12},{"id":"c19ac7d8","cell_type":"code","source":"if torch.cuda.is_available():\n    accelerator_type = 'gpu'\n    devices_to_use = 1\nelse:\n    accelerator_type = 'cpu'\n    devices_to_use = 'auto'\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='train_macrof1',\n    dirpath=OUTPUT_DIR,\n    filename='logikaui_efficientformerl1-{epoch:02d}-{train_macrof1:.4f}',\n    save_top_k=1,\n    mode='max'\n)\nearly_stopping = EarlyStopping(\n    monitor='train_loss',\n    patience=15,\n    mode='min',\n)\nlr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n\ntrainer1 = pl.Trainer(\n    max_epochs=config[\"epochs\"],\n    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback],\n    logger=TensorBoardLogger(\"tb_logs\", name=\"efficientnet_exp\"),\n    accelerator=accelerator_type,\n    devices=devices_to_use,\n    log_every_n_steps=10,\n    deterministic=True,\n    # precision=16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:45.964141Z","iopub.execute_input":"2025-09-29T10:39:45.964508Z","iopub.status.idle":"2025-09-29T10:39:46.024759Z","shell.execute_reply.started":"2025-09-29T10:39:45.964483Z","shell.execute_reply":"2025-09-29T10:39:46.024235Z"}},"outputs":[],"execution_count":13},{"id":"1ad56595","cell_type":"markdown","source":"## Train","metadata":{}},{"id":"c3324805-104f-4284-8da7-7cc954a207bd","cell_type":"code","source":"class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:46.025365Z","iopub.execute_input":"2025-09-29T10:39:46.025560Z","iopub.status.idle":"2025-09-29T10:39:46.031422Z","shell.execute_reply.started":"2025-09-29T10:39:46.025544Z","shell.execute_reply":"2025-09-29T10:39:46.030594Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])"},"metadata":{}}],"execution_count":14},{"id":"9a5c98a3","cell_type":"code","source":"model = PL(Backbone(dropout=0.4, freeze=False, backbone=\"efficientformer_l1\"), class_weights=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:46.032375Z","iopub.execute_input":"2025-09-29T10:39:46.032926Z","iopub.status.idle":"2025-09-29T10:39:46.362909Z","shell.execute_reply.started":"2025-09-29T10:39:46.032902Z","shell.execute_reply":"2025-09-29T10:39:46.362052Z"}},"outputs":[{"name":"stdout","text":"param backbone unfreeze\n","output_type":"stream"}],"execution_count":15},{"id":"79ff809c-5385-40eb-b265-373ce7be595f","cell_type":"code","source":"# from torch.serialization import add_safe_globals\n\n# add_safe_globals([Backbone, PL])  # ✅ tambahkan kelas custommu\n\n# checkpoint = torch.load(\n#     \"/kaggle/input/train-logika/logikaui_efficientformerl1-epoch09-train_macrof10.8021.ckpt\",\n#     map_location=\"cpu\",\n#     weights_only=False\n# )\n# model.load_state_dict(checkpoint[\"state_dict\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:46.363782Z","iopub.execute_input":"2025-09-29T10:39:46.364098Z","iopub.status.idle":"2025-09-29T10:39:46.368168Z","shell.execute_reply.started":"2025-09-29T10:39:46.364071Z","shell.execute_reply":"2025-09-29T10:39:46.367303Z"}},"outputs":[],"execution_count":16},{"id":"6d142303","cell_type":"code","source":"trainer1.fit(model, train_loader, val_dataloaders=None, ckpt_path=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:39:46.369104Z","iopub.execute_input":"2025-09-29T10:39:46.369490Z","iopub.status.idle":"2025-09-29T11:52:40.294302Z","shell.execute_reply.started":"2025-09-29T10:39:46.369462Z","shell.execute_reply":"2025-09-29T11:52:40.293029Z"}},"outputs":[{"name":"stderr","text":"2025-09-29 10:39:47.062041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759142387.084459     128 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759142387.091285     128 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71834ac93ba43348063ee510f661e79"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;31m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_128/3289800947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"],"ename":"NameError","evalue":"name 'exit' is not defined","output_type":"error"}],"execution_count":17},{"id":"5fd6f46c-ce61-4c5f-bb9f-4df989d17759","cell_type":"code","source":"# zip_path = save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3)\n# print(\"Zip file:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.295473Z","iopub.status.idle":"2025-09-29T11:52:40.295754Z","shell.execute_reply.started":"2025-09-29T11:52:40.295631Z","shell.execute_reply":"2025-09-29T11:52:40.295646Z"}},"outputs":[],"execution_count":null},{"id":"738ba917","cell_type":"code","source":"if __name__ == \"__main__\":\n    preds = trainer1.predict(model, test_loader)\n    print(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.297207Z","iopub.status.idle":"2025-09-29T11:52:40.297547Z","shell.execute_reply.started":"2025-09-29T11:52:40.297382Z","shell.execute_reply":"2025-09-29T11:52:40.297396Z"}},"outputs":[],"execution_count":null},{"id":"4f001afb","cell_type":"code","source":"predictions = []\nfor batch_result in preds:\n    image_names = batch_result['image_names']\n    preds = batch_result['preds'].cpu().numpy() \n    \n    for name, label in zip(image_names, preds):\n        predictions.append({\n            'id': name,     \n            'style': label  \n        })\npredictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.298878Z","iopub.status.idle":"2025-09-29T11:52:40.299144Z","shell.execute_reply.started":"2025-09-29T11:52:40.299019Z","shell.execute_reply":"2025-09-29T11:52:40.299033Z"}},"outputs":[],"execution_count":null},{"id":"3da01ac3-565b-4a53-90f7-6730ac16ea1a","cell_type":"code","source":"submission_df = pd.DataFrame(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.300145Z","iopub.status.idle":"2025-09-29T11:52:40.300508Z","shell.execute_reply.started":"2025-09-29T11:52:40.300321Z","shell.execute_reply":"2025-09-29T11:52:40.300339Z"}},"outputs":[],"execution_count":null},{"id":"4a9f8d91-ee0e-4b98-833c-0615ed20cc7d","cell_type":"code","source":"class_mapping = {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nidx_to_class = {v: k for k, v in class_mapping.items()}\nprint(f\"Tipe data kolom 'style': {submission_df['style'].dtype}\")\nsubmission_df['id'] = submission_df['id'].str.split('.').str[0]\n\nprint(f\"Nilai unik di kolom 'style': {submission_df['style'].unique()}\")\nsubmission_df['style'] = submission_df['style'].map(idx_to_class)\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.301783Z","iopub.status.idle":"2025-09-29T11:52:40.302073Z","shell.execute_reply.started":"2025-09-29T11:52:40.301954Z","shell.execute_reply":"2025-09-29T11:52:40.301967Z"}},"outputs":[],"execution_count":null},{"id":"6ced9ca8-ef3c-4aa6-b915-1e4272a0c6fd","cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T11:52:40.302920Z","iopub.status.idle":"2025-09-29T11:52:40.303216Z","shell.execute_reply.started":"2025-09-29T11:52:40.303043Z","shell.execute_reply":"2025-09-29T11:52:40.303058Z"}},"outputs":[],"execution_count":null},{"id":"57a07a0a-b589-4fb8-b9f3-f78788195eac","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c0049ef0-3a2b-47c5-a0e6-e13651a15fbf","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7f809574-4175-4c96-b25e-62e55033a5e9","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c360b12b-9915-469a-83ee-337f5b9d143c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a0bba659-b356-407a-ad39-eb6e01833725","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}