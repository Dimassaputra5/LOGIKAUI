{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13156543,"sourceType":"datasetVersion","datasetId":8336088},{"sourceId":13182263,"sourceType":"datasetVersion","datasetId":8353851}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c8a7b00d","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import models\n\nfrom torchvision import models\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, Callback\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom torchmetrics.classification import MulticlassAccuracy, F1Score\n!uv pip install pytorch_optimizer\nimport pytorch_optimizer as optim1\n\npl.seed_everything(42)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-09-27T08:16:21.313030Z","iopub.execute_input":"2025-09-27T08:16:21.313304Z","iopub.status.idle":"2025-09-27T08:16:27.681642Z","shell.execute_reply.started":"2025-09-27T08:16:21.313279Z","shell.execute_reply":"2025-09-27T08:16:27.680908Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 161ms\u001b[0m\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"63f65c46","cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\n\nclass AlbumentationsImageFolder(ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform=None)  # disable default transform\n        self.albumentations_transform = transform\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        image = self.loader(path)  # default loader (PIL)\n        image = np.array(image)    # PIL → NumPy\n        if self.albumentations_transform:\n            image = self.albumentations_transform(image=image)[\"image\"]\n        return image, label\n\n\nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Path ke direktori berisi semua gambar test.\n            transform (callable, optional): Transformasi Albumentations yang akan diterapkan pada gambar.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n        self.image_files = sorted([\n            f for f in os.listdir(root_dir) \n            if os.path.isfile(os.path.join(root_dir, f)) \n            and os.path.splitext(f)[1].lower() in allowed_extensions\n        ])\n\n    def __len__(self):\n        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Mengambil satu item data.\n\n        Args:\n            idx (int): Indeks dari item.\n        \n        Returns:\n            tuple: (image_tensor, image_name)\n        \"\"\"\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        image = np.array(image)  # PIL → NumPy (H, W, C)\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n\n        image_name = self.image_files[idx]\n        return image, image_name","metadata":{"execution":{"iopub.status.busy":"2025-09-27T08:16:27.682710Z","iopub.execute_input":"2025-09-27T08:16:27.683526Z","iopub.status.idle":"2025-09-27T08:16:27.692195Z","shell.execute_reply.started":"2025-09-27T08:16:27.683488Z","shell.execute_reply":"2025-09-27T08:16:27.691576Z"},"trusted":true},"outputs":[],"execution_count":2},{"id":"8be3aa77-d154-4a0c-a364-693526f20b23","cell_type":"code","source":"weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\nauto_transforms = weights.transforms()\nprint(auto_transforms)","metadata":{"execution":{"iopub.status.busy":"2025-09-27T08:16:27.693176Z","iopub.execute_input":"2025-09-27T08:16:27.693467Z","iopub.status.idle":"2025-09-27T08:16:27.715036Z","shell.execute_reply.started":"2025-09-27T08:16:27.693445Z","shell.execute_reply":"2025-09-27T08:16:27.714275Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BICUBIC\n)\n","output_type":"stream"}],"execution_count":3},{"id":"7e664d77","cell_type":"code","source":"train_transform = A.Compose([\n    A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),\n    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, min_holes=1, fill_value=0, p=0.5),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nbs = 32\ndata_train = '/kaggle/input/logika/Train/Train'\n\ntrain_dataset = AlbumentationsImageFolder(root=data_train, transform=train_transform)\nlabels = train_dataset.targets\nclass_counts = torch.bincount(torch.tensor(labels))\nprint(f\"Pemetaan kelas: {train_dataset.class_to_idx}\")\nprint(f\"Jumlah sampel per kelas: {class_counts}\")\nclass_weights = 1.0 / class_counts.float()\nprint(f\"Bobot untuk setiap kelas: {class_weights}\")\nweights_per_sample = class_weights[labels]\nprint(f\"Panjang bobot per sampel: {len(weights_per_sample)}\")\nprint(\"Contoh 5 bobot pertama:\", weights_per_sample[:5])\n\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(train_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-27T08:16:27.717001Z","iopub.execute_input":"2025-09-27T08:16:27.717253Z","iopub.status.idle":"2025-09-27T08:16:28.526232Z","shell.execute_reply.started":"2025-09-27T08:16:27.717236Z","shell.execute_reply":"2025-09-27T08:16:28.525498Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Pemetaan kelas: {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nJumlah sampel per kelas: tensor([776,  95,  69, 249, 563])\nBobot untuk setiap kelas: tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])\nPanjang bobot per sampel: 1752\nContoh 5 bobot pertama: tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0013])\nJumlah data test: 1752\n","output_type":"stream"}],"execution_count":4},{"id":"b58622c1","cell_type":"code","source":"data_test_dir = '/kaggle/input/logika/Test/Test'\n\ntest_dataset = TestDataset(root_dir=data_test_dir, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(test_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-09-27T08:16:28.527008Z","iopub.execute_input":"2025-09-27T08:16:28.527240Z","iopub.status.idle":"2025-09-27T08:16:28.761415Z","shell.execute_reply.started":"2025-09-27T08:16:28.527222Z","shell.execute_reply":"2025-09-27T08:16:28.760840Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Jumlah data test: 444\n","output_type":"stream"}],"execution_count":5},{"id":"79885754","cell_type":"code","source":"label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\nlabel2cat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.783849Z","iopub.execute_input":"2025-09-27T08:16:28.784065Z","iopub.status.idle":"2025-09-27T08:16:28.801248Z","shell.execute_reply.started":"2025-09-27T08:16:28.784049Z","shell.execute_reply":"2025-09-27T08:16:28.800608Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}"},"metadata":{}}],"execution_count":8},{"id":"c33863dd","cell_type":"markdown","source":"## Arsitektur dan config","metadata":{}},{"id":"679c7a9f","cell_type":"code","source":"def conv_block(in_feature, out_feature, padding=1, stride=1,\n             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n    if activation == \"relu\":\n        layers.append(nn.ReLU())\n    elif activation == \"leakyrelu\":\n        layers.append(nn.LeakyReLU())\n    elif activation == \"sigmoid\":\n        layers.append(nn.Sigmoid())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == \"tanh\":\n        layers.append(nn.Tanh())\n    if pool:\n        if maxpool:\n            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n        else:\n            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n    else:\n        layers.append(nn.Identity())\n    return nn.Sequential(*layers)\n\n\ndef linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n    layers = [nn.Linear(in_features, out_features)]\n    if batch_norm:\n        layers.append(nn.BatchNorm1d(out_features))\n    if activation == 'relu':\n        layers.append(nn.ReLU())\n    elif activation == 'sigmoid':\n        layers.append(nn.Sigmoid())\n    elif activation == 'tanh':\n        layers.append(nn.Tanh())\n    elif activation == 'leakyrelu':\n        layers.append(nn.LeakyReLU())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == 'gelu': layers.append(nn.GELU())\n    elif activation == 'softmax':\n        layers.append(nn.Softmax(dim=1))\n    elif activation == 'elu':\n        layers.append(nn.ELU())\n    elif activation == 'selu':\n        layers.append(nn.SELU())\n    elif activation == 'lsoftmax':\n        layers.append(nn.LogSoftmax(dim=1))\n    if dropout > 0.0:\n        layers.append(nn.Dropout(dropout))\n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.802045Z","iopub.execute_input":"2025-09-27T08:16:28.802535Z","iopub.status.idle":"2025-09-27T08:16:28.816010Z","shell.execute_reply.started":"2025-09-27T08:16:28.802509Z","shell.execute_reply":"2025-09-27T08:16:28.815362Z"}},"outputs":[],"execution_count":9},{"id":"27a449c0","cell_type":"code","source":"class EfficientNet(nn.Module):\n    def __init__(self, dropout=0.0, freeze=True):\n        super().__init__()\n        \n        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        self.backbone = models.efficientnet_b0(weights=weights).features\n        if freeze:\n            for param in self.backbone.parameters():\n                param.requires_grad = False\n        else:\n            for param in self.backbone[-3:].parameters():\n                print(f'param 30% train')\n                param.requires_grad = True     \n        self.classifier = nn.Sequential(\n            linear_block(1280, 128, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(128, 5, activation=None)\n        )\n    def forward(self, X):\n        X = self.backbone(X)\n        X = X.mean([2, 3])  \n        return self.classifier(X)\n        \nclass PL(LightningModule):\n    def __init__(self, model, class_weights, learning_rate=1e-3) -> None:\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = model\n        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n    \n    def forward(self, X):\n        return self.model(X)\n    \n    def _common_step(self, batch, batch_idx):\n        X, labels = batch\n        outputs = self(X) \n        loss = self.criterion(outputs, labels)\n        macrof1 = self.macroF1(outputs, labels)\n        return loss, macrof1\n\n    def training_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_macrof1', macroF1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=1e-4)\n        scheduler = CosineAnnealingLR(optimizer, T_max=10)\n        return [optimizer], [scheduler]\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        \"\"\"\n        Langkah prediksi untuk satu batch data test.\n        \"\"\"\n        images, image_names = batch\n        outputs = self.forward(images)\n        _, predicted_labels = torch.max(outputs, 1)\n        return {\"image_names\": image_names, \"preds\": predicted_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.816657Z","iopub.execute_input":"2025-09-27T08:16:28.816862Z","iopub.status.idle":"2025-09-27T08:16:28.834413Z","shell.execute_reply.started":"2025-09-27T08:16:28.816848Z","shell.execute_reply":"2025-09-27T08:16:28.833701Z"}},"outputs":[],"execution_count":10},{"id":"2564e101","cell_type":"code","source":"import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import Callback\n\nclass FineTuningCallback(Callback):\n    def __init__(self, unfreeze_at_epoch=8, backbone_lr=5e-5, head_lr=1e-4):\n        super().__init__()\n        self.unfreeze_at_epoch = unfreeze_at_epoch\n        self.backbone_lr = backbone_lr\n        self.head_lr = head_lr\n\n    def on_train_epoch_start(self, trainer, pl_module):\n        if trainer.current_epoch != self.unfreeze_at_epoch:\n            return\n        \n        print(f\"\\n--- Epoch {self.unfreeze_at_epoch}: Fine-tuning diaktifkan! ---\")\n        backbone_layers = list(pl_module.model.backbone.children())\n        n_layers = len(backbone_layers)\n        cut_point = int(n_layers * 0.7)\n        for param in pl_module.model.backbone.parameters():\n            param.requires_grad = False\n        for layer in backbone_layers[cut_point:]:\n            for param in layer.parameters():\n                param.requires_grad = True\n        optimizer = trainer.optimizers[0]\n        defaults = optimizer.defaults\n        param_groups = [\n            {**defaults, \"params\": pl_module.model.backbone.parameters(), \"lr\": self.backbone_lr},\n            {**defaults, \"params\": pl_module.model.classifier.parameters(), \"lr\": self.head_lr}\n        ]\n        optimizer.param_groups = param_groups\n        \n        print(f\"Optimizer dikonfigurasi ulang dengan LR backbone={self.backbone_lr} dan LR head={self.head_lr}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.835196Z","iopub.execute_input":"2025-09-27T08:16:28.835431Z","iopub.status.idle":"2025-09-27T08:16:28.854794Z","shell.execute_reply.started":"2025-09-27T08:16:28.835411Z","shell.execute_reply":"2025-09-27T08:16:28.854074Z"}},"outputs":[],"execution_count":11},{"id":"dbe4a619-7207-4c4c-9174-0ee67e6a0386","cell_type":"code","source":"import json\nimport yaml\nimport subprocess\nimport shutil\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nKAGGLE_USERNAME = \"dimassp1\"\nDATASET_NAME = \"efficientnet-training-output\"\nDATASET_SLUG = f\"{KAGGLE_USERNAME}/{DATASET_NAME}\"\n\nconfig = {\n    \"architecture\": \"EfficientNet-B0\",\n    \"dropout\": 0.3,\n    \"freeze\": False,\n    \"optimizer\": \"AdamW\",\n    \"optimizer_params\": {\"lr\": 1e-3},\n    \"loss_function\": \"CrossEntropyLoss\",\n    \"metrics\": [\"F1Score_macro\"],\n    \"epochs\": 50,\n    \"batch_size\": bs,\n    \"input_size\": (224, 224),\n    \"num_classes\": 5\n}\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\n\nimport os, shutil, torch, yaml, zipfile\n\ndef save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    best_ckpt_path = checkpoint_callback.best_model_path\n    if best_ckpt_path and os.path.exists(best_ckpt_path):\n        checkpoint_file = os.path.basename(best_ckpt_path)  \n        dst_path = os.path.join(output_dir, checkpoint_file)\n\n        if os.path.abspath(best_ckpt_path) != os.path.abspath(dst_path):\n            shutil.copy(best_ckpt_path, dst_path)\n        else:\n            print(f\"ℹ️ Checkpoint sudah ada di {output_dir}, tidak perlu copy ulang.\")\n\n    else:\n        print(\"⚠️ Best checkpoint belum ada, file .ckpt tidak disalin.\")\n\n    full_state_dict = model.state_dict()\n    backbone_state_dict = {}\n    backbone_keys = [k for k in full_state_dict.keys() if k.startswith(\"features.\")]\n    num_keys_to_save = max(1, int(len(backbone_keys) * backbone_ratio))\n\n    for k in backbone_keys[:num_keys_to_save]:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    head_keys = [k for k in full_state_dict.keys() if k.startswith(\"classifier.\")]\n    for k in head_keys:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    torch.save(backbone_state_dict, os.path.join(output_dir, \"efficientnet_partial_state_dict.pt\"))\n\n    with open(os.path.join(output_dir, \"config.yaml\"), \"w\") as f:\n        yaml.dump(config, f)\n\n    zip_path = os.path.join(output_dir, \"output_dataset.zip\")\n    files_to_zip = [\n        f for f in [\"config.yaml\", \"efficientnet_partial_state_dict.pt\"] \n        if os.path.exists(os.path.join(output_dir, f))\n    ]\n    if best_ckpt_path:\n        files_to_zip.append(os.path.basename(best_ckpt_path))\n\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for f in files_to_zip:\n            file_path = os.path.join(output_dir, f)\n            zipf.write(file_path, arcname=f)\n\n    print(f\"✅ Semua output sudah di-zip: {zip_path}\")\n    return zip_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.855766Z","iopub.execute_input":"2025-09-27T08:16:28.855973Z","iopub.status.idle":"2025-09-27T08:16:28.874256Z","shell.execute_reply.started":"2025-09-27T08:16:28.855956Z","shell.execute_reply":"2025-09-27T08:16:28.873607Z"}},"outputs":[],"execution_count":12},{"id":"c19ac7d8","cell_type":"code","source":"if torch.cuda.is_available():\n    accelerator_type = 'gpu'\n    devices_to_use = 1\nelse:\n    accelerator_type = 'cpu'\n    devices_to_use = 'auto'\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='train_macrof1',\n    dirpath=OUTPUT_DIR,\n    filename='logikaui-{epoch:02d}-{train_macrof1:.4f}',\n    save_top_k=1,\n    mode='max'\n)\nearly_stopping = EarlyStopping(\n    monitor='train_loss',\n    patience=5,\n    mode='min',\n)\nlr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\nfine_tune_callback = FineTuningCallback(unfreeze_at_epoch=20, backbone_lr=3e-5, head_lr=5e-4)\n\ntrainer1 = pl.Trainer(\n    max_epochs=config[\"epochs\"],\n    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback, fine_tune_callback],\n    logger=TensorBoardLogger(\"tb_logs\", name=\"efficientnet_exp\"),\n    accelerator=accelerator_type,\n    devices=devices_to_use,\n    log_every_n_steps=10,\n    deterministic=True,\n    # precision=16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.876746Z","iopub.execute_input":"2025-09-27T08:16:28.877172Z","iopub.status.idle":"2025-09-27T08:16:28.940314Z","shell.execute_reply.started":"2025-09-27T08:16:28.877156Z","shell.execute_reply":"2025-09-27T08:16:28.939481Z"}},"outputs":[],"execution_count":13},{"id":"1ad56595","cell_type":"markdown","source":"## Train","metadata":{}},{"id":"c3324805-104f-4284-8da7-7cc954a207bd","cell_type":"code","source":"class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.941213Z","iopub.execute_input":"2025-09-27T08:16:28.941457Z","iopub.status.idle":"2025-09-27T08:16:28.947942Z","shell.execute_reply.started":"2025-09-27T08:16:28.941436Z","shell.execute_reply":"2025-09-27T08:16:28.947172Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])"},"metadata":{}}],"execution_count":14},{"id":"9a5c98a3","cell_type":"code","source":"model = PL(EfficientNet(dropout=0.3, freeze=True), class_weights=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:28.948869Z","iopub.execute_input":"2025-09-27T08:16:28.949120Z","iopub.status.idle":"2025-09-27T08:16:29.201335Z","shell.execute_reply.started":"2025-09-27T08:16:28.949099Z","shell.execute_reply":"2025-09-27T08:16:29.200718Z"}},"outputs":[],"execution_count":15},{"id":"6d142303","cell_type":"code","source":"trainer1.fit(model, train_loader, val_dataloaders=None, ckpt_path='last')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:16:29.202060Z","iopub.execute_input":"2025-09-27T08:16:29.202319Z"}},"outputs":[{"name":"stderr","text":"2025-09-27 08:16:30.107930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758960990.129011     136 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758960990.136740     136 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b62702079d924140ae0ef77ac2e956bc"}},"metadata":{}}],"execution_count":null},{"id":"5fd6f46c-ce61-4c5f-bb9f-4df989d17759","cell_type":"code","source":"zip_path = save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3)\nprint(\"Zip file:\", zip_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"738ba917","cell_type":"code","source":"if __name__ == \"__main__\":\n    preds = trainer1.predict(model, test_loader, ckpt_path='best')\n    print(preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4f001afb","cell_type":"code","source":"predictions = []\nfor batch_result in preds:\n    image_names = batch_result['image_names']\n    preds = batch_result['preds'].cpu().numpy() \n    \n    for name, label in zip(image_names, preds):\n        predictions.append({\n            'id': name,     \n            'style': label  \n        })\npredictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3da01ac3-565b-4a53-90f7-6730ac16ea1a","cell_type":"code","source":"submission_df = pd.DataFrame(predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4a9f8d91-ee0e-4b98-833c-0615ed20cc7d","cell_type":"code","source":"class_mapping = {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nidx_to_class = {v: k for k, v in class_mapping.items()}\nprint(f\"Tipe data kolom 'style': {submission_df['style'].dtype}\")\nsubmission_df['id'] = submission_df['id'].str.split('.').str[0]\n\nprint(f\"Nilai unik di kolom 'style': {submission_df['style'].unique()}\")\nsubmission_df['style'] = submission_df['style'].map(idx_to_class)\nsubmission_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6ced9ca8-ef3c-4aa6-b915-1e4272a0c6fd","cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"57a07a0a-b589-4fb8-b9f3-f78788195eac","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c0049ef0-3a2b-47c5-a0e6-e13651a15fbf","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7f809574-4175-4c96-b25e-62e55033a5e9","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c360b12b-9915-469a-83ee-337f5b9d143c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a0bba659-b356-407a-ad39-eb6e01833725","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}