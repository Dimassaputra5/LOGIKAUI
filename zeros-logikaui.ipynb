{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a7b00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:52.961077Z",
     "iopub.status.busy": "2025-09-24T16:48:52.960332Z",
     "iopub.status.idle": "2025-09-24T16:48:58.712885Z",
     "shell.execute_reply": "2025-09-24T16:48:58.712020Z",
     "shell.execute_reply.started": "2025-09-24T16:48:52.961053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, Callback\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy, F1Score\n",
    "# !uv pip install pytorch_optimizer\n",
    "import pytorch_optimizer as optim1\n",
    "\n",
    "pl.seed_everything(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f65c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:58.715054Z",
     "iopub.status.busy": "2025-09-24T16:48:58.714413Z",
     "iopub.status.idle": "2025-09-24T16:48:58.722284Z",
     "shell.execute_reply": "2025-09-24T16:48:58.721586Z",
     "shell.execute_reply.started": "2025-09-24T16:48:58.715030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Path ke direktori berisi semua gambar test.\n",
    "            transform (callable, optional): Transformasi yang akan diterapkan pada gambar.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n",
    "        self.image_files = sorted([\n",
    "        f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f)) and os.path.splitext(f)[1].lower() in allowed_extensions\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Mengambil satu item data.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Indeks dari item.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (image, image_name) di mana image_name adalah nama file.\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        image_name = self.image_files[idx]\n",
    "        return image, image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be3aa77-d154-4a0c-a364-693526f20b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:58.723647Z",
     "iopub.status.busy": "2025-09-24T16:48:58.723091Z",
     "iopub.status.idle": "2025-09-24T16:48:58.745385Z",
     "shell.execute_reply": "2025-09-24T16:48:58.744742Z",
     "shell.execute_reply.started": "2025-09-24T16:48:58.723624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "auto_transforms = weights.transforms()\n",
    "print(auto_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e664d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:58.747128Z",
     "iopub.status.busy": "2025-09-24T16:48:58.746865Z",
     "iopub.status.idle": "2025-09-24T16:48:59.544597Z",
     "shell.execute_reply": "2025-09-24T16:48:59.543921Z",
     "shell.execute_reply.started": "2025-09-24T16:48:58.747087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemetaan kelas: {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\n",
      "Jumlah sampel per kelas: tensor([776,  95,  69, 249, 563])\n",
      "Bobot untuk setiap kelas: tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])\n",
      "Panjang bobot per sampel: 1752\n",
      "Contoh 5 bobot pertama: tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0013])\n",
      "Jumlah data test: 1752\n"
     ]
    }
   ],
   "source": [
    "train= transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomPerspective(),\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "            transforms.ColorJitter(),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            auto_transforms\n",
    "])\n",
    "val = transforms.Compose([\n",
    "        auto_transforms\n",
    "])\n",
    "data_train = 'dsc-logika-ui-2025\\Train\\Train'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=data_train, transform=train)\n",
    "labels = train_dataset.targets\n",
    "class_counts = torch.bincount(torch.tensor(labels))\n",
    "print(f\"Pemetaan kelas: {train_dataset.class_to_idx}\")\n",
    "print(f\"Jumlah sampel per kelas: {class_counts}\")\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "print(f\"Bobot untuk setiap kelas: {class_weights}\")\n",
    "weights_per_sample = class_weights[labels]\n",
    "print(f\"Panjang bobot per sampel: {len(weights_per_sample)}\")\n",
    "print(\"Contoh 5 bobot pertama:\", weights_per_sample[:5])\n",
    "\n",
    "sampler = WeightedRandomSampler(weights_per_sample, num_samples=len(weights_per_sample), replacement=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, sampler=sampler)\n",
    "print(f'Jumlah data test: {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab43021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = datasets.ImageFolder(root='dataset_split/validation', transform=val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# print(f'Jumlah data test: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58622c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:59.545543Z",
     "iopub.status.busy": "2025-09-24T16:48:59.545291Z",
     "iopub.status.idle": "2025-09-24T16:48:59.758182Z",
     "shell.execute_reply": "2025-09-24T16:48:59.757549Z",
     "shell.execute_reply.started": "2025-09-24T16:48:59.545525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data test: 444\n"
     ]
    }
   ],
   "source": [
    "data_test_dir = 'dsc-logika-ui-2025\\Test\\Test'\n",
    "\n",
    "test_dataset = TestDataset(root_dir=data_test_dir, transform=val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "print(f'Jumlah data test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a122c5-e7b2-42ed-aed7-9a77b1230c57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T16:48:59.759131Z",
     "iopub.status.busy": "2025-09-24T16:48:59.758902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# feature, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ebf143",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# feature.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79885754",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\n",
    "label2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33863dd",
   "metadata": {},
   "source": [
    "## Arsitektur dan config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679c7a9f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conv_block(in_feature, out_feature, padding=1, stride=1,\n",
    "             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n",
    "             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n",
    "    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n",
    "    if activation == \"relu\":\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == \"leakyrelu\":\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == \"sigmoid\":\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == 'mish': layers.append(nn.Mish())\n",
    "    elif activation == \"tanh\":\n",
    "        layers.append(nn.Tanh())\n",
    "    if pool:\n",
    "        if maxpool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "        else:\n",
    "            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "    else:\n",
    "        layers.append(nn.Identity())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n",
    "    layers = [nn.Linear(in_features, out_features)]\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm1d(out_features))\n",
    "    if activation == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == 'sigmoid':\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == 'tanh':\n",
    "        layers.append(nn.Tanh())\n",
    "    elif activation == 'leakyrelu':\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == 'mish': layers.append(nn.Mish())\n",
    "    elif activation == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif activation == 'elu':\n",
    "        layers.append(nn.ELU())\n",
    "    elif activation == 'selu':\n",
    "        layers.append(nn.SELU())\n",
    "    elif activation == 'lsoftmax':\n",
    "        layers.append(nn.LogSoftmax(dim=1))\n",
    "    if dropout > 0.0:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a449c0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, dropout=0.0, freeze=True):\n",
    "        super().__init__()\n",
    "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        self.backbone = models.efficientnet_b0(weights=weights).features\n",
    "        if freeze:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.classifier = nn.Sequential(\n",
    "            linear_block(1280, 256, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(256, 128, activation='mish', dropout=dropout, batch_norm=True),\n",
    "            linear_block(128, 5, activation=None)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        X = self.backbone(X)\n",
    "        X = X.mean([2, 3])  \n",
    "        return self.classifier(X)\n",
    "        \n",
    "class PL(LightningModule):\n",
    "    def __init__(self, model, learning_rate, class_weights) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        X, labels = batch\n",
    "        outputs = self(X) \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        macrof1 = self.macroF1(outputs, labels)\n",
    "        return loss, macrof1\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_macrof1', macroF1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, macroF1 = self._common_step(batch, batch_idx)\n",
    "        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    # def backward(self, loss, *args, **kwargs):\n",
    "    #     loss.backward(create_graph=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim1.Lion(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        \"\"\"\n",
    "        Langkah prediksi untuk satu batch data test.\n",
    "        \"\"\"\n",
    "        images, image_names = batch\n",
    "        outputs = self.forward(images)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        return {\"image_names\": image_names, \"preds\": predicted_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2564e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class FineTuningCallback(Callback):\n",
    "    def __init__(self, unfreeze_at_epoch=8, backbone_lr=1e-5, head_lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.unfreeze_at_epoch = unfreeze_at_epoch\n",
    "        self.backbone_lr = backbone_lr\n",
    "        self.head_lr = head_lr\n",
    "\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        if trainer.current_epoch != self.unfreeze_at_epoch:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n--- Epoch {self.unfreeze_at_epoch}: Fine-tuning diaktifkan! ---\")\n",
    "        \n",
    "        # 1. Cairkan (unfreeze) semua parameter di model\n",
    "        for param in pl_module.model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # 2. Dapatkan optimizer saat ini\n",
    "        optimizer = trainer.optimizers[0]\n",
    "        \n",
    "        # --- PERBAIKAN DIMULAI DI SINI ---\n",
    "        \n",
    "        # 3. Ambil hyperparameter default dari optimizer (termasuk 'betas')\n",
    "        defaults = optimizer.defaults\n",
    "        \n",
    "        # 4. Buat param_groups baru dengan menyertakan defaults tersebut,\n",
    "        #    lalu timpa 'params' dan 'lr' sesuai kebutuhan.\n",
    "        param_groups = [\n",
    "            # Grup untuk backbone: salin defaults, lalu timpa lr dan params\n",
    "            {**defaults, \"params\": pl_module.model.backbone.parameters(), \"lr\": self.backbone_lr},\n",
    "            \n",
    "            # Grup untuk classifier head\n",
    "            {**defaults, \"params\": pl_module.model.classifier.parameters(), \"lr\": self.head_lr}\n",
    "        ]\n",
    "        \n",
    "        # --- AKHIR DARI PERBAIKAN ---\n",
    "        \n",
    "        # 5. Hapus param_groups yang lama dan ganti dengan yang baru\n",
    "        optimizer.param_groups = param_groups\n",
    "        \n",
    "        print(f\"Optimizer dikonfigurasi ulang dengan LR backbone={self.backbone_lr} dan LR head={self.head_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c19ac7d8",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator_type = 'gpu'\n",
    "    devices_to_use = 1\n",
    "else:\n",
    "    accelerator_type = 'cpu'\n",
    "    devices_to_use = 'auto'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_macrof1',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='logikaui-{epoch:02d}-{train_macrof1:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='train_loss',\n",
    "    patience=11,\n",
    "    mode='min',\n",
    ")\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n",
    "fine_tune_callback = FineTuningCallback(unfreeze_at_epoch=8, backbone_lr=1e-5, head_lr=3e-4)\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback, fine_tune_callback],\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"simple_model_experiment\"),\n",
    "    accelerator=accelerator_type,\n",
    "    devices=devices_to_use,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True,\n",
    "    precision='16-mixed'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad56595",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3324805-104f-4284-8da7-7cc954a207bd",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a5c98a3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = PL(EfficientNet(dropout=0.1, freeze=True), learning_rate=5e-4, class_weights=class_weights)\n",
    "# model = torch.compile(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d142303",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | EfficientNet      | 4.4 M  | train\n",
      "1 | criterion | CrossEntropyLoss  | 0      | train\n",
      "2 | macroF1   | MulticlassF1Score | 0      | train\n",
      "--------------------------------------------------------\n",
      "362 K     Trainable params\n",
      "4.0 M     Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.479    Total estimated model params size (MB)\n",
      "348       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197b92c2a77c4084a7bfab8c3900337d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer1.fit(model, train_loader, val_dataloaders=None, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ba917",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    preds = trainer1.predict(model, test_loader, ckpt_path='best')\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f001afb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for batch_result in preds:\n",
    "    # batch_result adalah dictionary yang kita return dari predict_step\n",
    "    image_names = batch_result['image_names']\n",
    "    preds = batch_result['preds'].cpu().numpy() # Pindahkan ke CPU\n",
    "    \n",
    "    for name, label in zip(image_names, preds):\n",
    "        predictions.append({\n",
    "            'id': name,      # Nama kolom sesuai standar Kaggle\n",
    "            'style': label   # Nama kolom sesuai standar Kaggle\n",
    "        })\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da01ac3-565b-4a53-90f7-6730ac16ea1a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f8d91-ee0e-4b98-833c-0615ed20cc7d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_mapping = {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\n",
    "idx_to_class = {v: k for k, v in class_mapping.items()}\n",
    "# Cek tipe data dari kolom 'style'. Kemungkinan besar hasilnya 'object' (string).\n",
    "print(f\"Tipe data kolom 'style': {submission_df['style'].dtype}\")\n",
    "submission_df['id'] = submission_df['id'].str.split('.').str[0]\n",
    "\n",
    "# Lihat nilai-nilai unik di dalam kolom tersebut.\n",
    "# Perhatikan apakah ada tanda kutip, yang menandakan string.\n",
    "print(f\"Nilai unik di kolom 'style': {submission_df['style'].unique()}\")\n",
    "submission_df['style'] = submission_df['style'].map(idx_to_class)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced9ca8-ef3c-4aa6-b915-1e4272a0c6fd",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a07a0a-b589-4fb8-b9f3-f78788195eac",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13809662,
     "sourceId": 115446,
     "sourceType": "competition"
    },
    {
     "datasetId": 8336088,
     "sourceId": 13156543,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dmsdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
