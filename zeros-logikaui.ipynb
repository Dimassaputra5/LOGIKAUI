{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13156543,"sourceType":"datasetVersion","datasetId":8336088},{"sourceId":13182263,"sourceType":"datasetVersion","datasetId":8353851},{"sourceId":13226398,"sourceType":"datasetVersion","datasetId":8356889}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c8a7b00d","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport timm\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import models\n\nfrom torchvision import models\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor, Callback\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom torchmetrics.classification import MulticlassAccuracy, F1Score\n!uv pip install pytorch_optimizer\nimport pytorch_optimizer as optim1\n\n","metadata":{"execution":{"iopub.status.busy":"2025-10-01T11:41:55.491365Z","iopub.execute_input":"2025-10-01T11:41:55.492010Z","iopub.status.idle":"2025-10-01T11:42:34.590501Z","shell.execute_reply.started":"2025-10-01T11:41:55.491980Z","shell.execute_reply":"2025-10-01T11:42:34.589636Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m36 packages\u001b[0m \u001b[2min 1.07s\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m     0 B/257.74 KiB             \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 14.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 30.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 46.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 62.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 78.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 94.91 KiB/257.74 KiB           \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 110.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 126.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 142.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----------\u001b[0m\u001b[0m 158.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)2m---------\u001b[0m\u001b[0m 174.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m-------\u001b[0m\u001b[0m 190.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--\u001b[2m-----\u001b[0m\u001b[0m 206.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---\u001b[2m----\u001b[0m\u001b[0m 222.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----\u001b[2m--\u001b[0m\u001b[0m 238.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------\u001b[2m\u001b[0m\u001b[0m 254.91 KiB/257.74 KiB          \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 90ms\u001b[0m\u001b[0m                                                   \u001b[1A\n\u001b[2mUninstalled \u001b[1m10 packages\u001b[0m \u001b[2min 35ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m11 packages\u001b[0m \u001b[2min 16.58s\u001b[0m\u001b[0m.0.70                        \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytorch-optimizer\u001b[0m\u001b[2m==3.8.0\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"1854dab9-291e-4281-9a7c-1739c9672c90","cell_type":"code","source":"pl.seed_everything(42)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:34.592367Z","iopub.execute_input":"2025-10-01T11:42:34.593854Z","iopub.status.idle":"2025-10-01T11:42:34.607018Z","shell.execute_reply.started":"2025-10-01T11:42:34.593826Z","shell.execute_reply":"2025-10-01T11:42:34.606298Z"}},"outputs":[],"execution_count":2},{"id":"63f65c46","cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\n\nclass AlbumentationsImageFolder(ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform=None)  # disable default transform\n        self.albumentations_transform = transform\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        image = self.loader(path)  # default loader (PIL)\n        image = np.array(image)    # PIL → NumPy\n        if self.albumentations_transform:\n            image = self.albumentations_transform(image=image)[\"image\"]\n        return image, label\n\n\nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): Path ke direktori berisi semua gambar test.\n            transform (callable, optional): Transformasi Albumentations yang akan diterapkan pada gambar.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n        self.image_files = sorted([\n            f for f in os.listdir(root_dir) \n            if os.path.isfile(os.path.join(root_dir, f)) \n            and os.path.splitext(f)[1].lower() in allowed_extensions\n        ])\n\n    def __len__(self):\n        \"\"\"Mengembalikan jumlah total gambar dalam dataset.\"\"\"\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Mengambil satu item data.\n\n        Args:\n            idx (int): Indeks dari item.\n        \n        Returns:\n            tuple: (image_tensor, image_name)\n        \"\"\"\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        image = np.array(image)  # PIL → NumPy (H, W, C)\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n\n        image_name = self.image_files[idx]\n        return image, image_name","metadata":{"execution":{"iopub.status.busy":"2025-10-01T11:42:34.607840Z","iopub.execute_input":"2025-10-01T11:42:34.608149Z","iopub.status.idle":"2025-10-01T11:42:34.618386Z","shell.execute_reply.started":"2025-10-01T11:42:34.608124Z","shell.execute_reply":"2025-10-01T11:42:34.617735Z"},"trusted":true},"outputs":[],"execution_count":3},{"id":"8be3aa77-d154-4a0c-a364-693526f20b23","cell_type":"code","source":"weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\nauto_transforms = weights.transforms()\nprint(auto_transforms)","metadata":{"execution":{"iopub.status.busy":"2025-10-01T11:42:34.620443Z","iopub.execute_input":"2025-10-01T11:42:34.620727Z","iopub.status.idle":"2025-10-01T11:42:34.638548Z","shell.execute_reply.started":"2025-10-01T11:42:34.620706Z","shell.execute_reply":"2025-10-01T11:42:34.637785Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BICUBIC\n)\n","output_type":"stream"}],"execution_count":4},{"id":"6cd7216d-919a-49bb-805e-20ecadcd0041","cell_type":"code","source":"normz = A.Normalize(mean=(0.5, 0.5, 0.5),std=(0.5, 0.5, 0.5))\nnormz1 = A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:34.639354Z","iopub.execute_input":"2025-10-01T11:42:34.639714Z","iopub.status.idle":"2025-10-01T11:42:34.655397Z","shell.execute_reply.started":"2025-10-01T11:42:34.639681Z","shell.execute_reply":"2025-10-01T11:42:34.654737Z"}},"outputs":[],"execution_count":5},{"id":"7e664d77","cell_type":"code","source":"train_transform = A.Compose([\n    A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),\n    A.OneOf([\n        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=1.0),\n        A.RandomBrightnessContrast(p=1.0),\n        A.HueSaturationValue(p=1.0),\n        A.RandomGamma(p=1.0),\n    ], p=0.7),\n    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, min_holes=1, fill_value=0, p=0.5),\n    A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n\nbs = 64\ndata_train = '/kaggle/input/logika/Train/Train'\n\ntrain_dataset = AlbumentationsImageFolder(root=data_train, transform=train_transform)\nlabels = train_dataset.targets\nclass_counts = torch.bincount(torch.tensor(labels))\nprint(f\"Pemetaan kelas: {train_dataset.class_to_idx}\")\nprint(f\"Jumlah sampel per kelas: {class_counts}\")\nclass_weights = 1.0 / class_counts.float()\nprint(f\"Bobot untuk setiap kelas: {class_weights}\")\nweights_per_sample = class_weights[labels]\nprint(f\"Panjang bobot per sampel: {len(weights_per_sample)}\")\nprint(\"Contoh 5 bobot pertama:\", weights_per_sample[:5])\n\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(train_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-10-01T11:42:34.656199Z","iopub.execute_input":"2025-10-01T11:42:34.656416Z","iopub.status.idle":"2025-10-01T11:42:39.474740Z","shell.execute_reply.started":"2025-10-01T11:42:34.656399Z","shell.execute_reply":"2025-10-01T11:42:39.473883Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Pemetaan kelas: {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nJumlah sampel per kelas: tensor([776,  95,  69, 249, 563])\nBobot untuk setiap kelas: tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])\nPanjang bobot per sampel: 1752\nContoh 5 bobot pertama: tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0013])\nJumlah data test: 1752\n","output_type":"stream"}],"execution_count":6},{"id":"b58622c1","cell_type":"code","source":"data_test_dir = '/kaggle/input/logika/Test/Test'\n\ntest_dataset = TestDataset(root_dir=data_test_dir, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=1, pin_memory=True)\nprint(f'Jumlah data test: {len(test_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2025-10-01T11:42:39.475519Z","iopub.execute_input":"2025-10-01T11:42:39.475965Z","iopub.status.idle":"2025-10-01T11:42:40.758134Z","shell.execute_reply.started":"2025-10-01T11:42:39.475938Z","shell.execute_reply":"2025-10-01T11:42:40.757368Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Jumlah data test: 444\n","output_type":"stream"}],"execution_count":7},{"id":"79885754","cell_type":"code","source":"label2cat, idxclass = train_dataset.class_to_idx, train_dataset.classes\nlabel2cat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.759039Z","iopub.execute_input":"2025-10-01T11:42:40.759407Z","iopub.status.idle":"2025-10-01T11:42:40.766421Z","shell.execute_reply.started":"2025-10-01T11:42:40.759377Z","shell.execute_reply":"2025-10-01T11:42:40.765566Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}"},"metadata":{}}],"execution_count":8},{"id":"c33863dd","cell_type":"markdown","source":"## Arsitektur dan config","metadata":{}},{"id":"679c7a9f","cell_type":"code","source":"def conv_block(in_feature, out_feature, padding=1, stride=1,\n             activation=\"relu\", pool =True, maxpool=True, kernel_size=3,\n             kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n    if activation == \"relu\":\n        layers.append(nn.ReLU())\n    elif activation == \"leakyrelu\":\n        layers.append(nn.LeakyReLU())\n    elif activation == \"sigmoid\":\n        layers.append(nn.Sigmoid())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == \"tanh\":\n        layers.append(nn.Tanh())\n    if pool:\n        if maxpool:\n            layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n        else:\n            layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n    else:\n        layers.append(nn.Identity())\n    return nn.Sequential(*layers)\n\n\ndef linear_block(in_features, out_features, activation=None, dropout=0.0, batch_norm=None):\n    layers = [nn.Linear(in_features, out_features)]\n    if batch_norm:\n        layers.append(nn.BatchNorm1d(out_features))\n    if activation == 'relu':\n        layers.append(nn.ReLU())\n    elif activation == 'sigmoid':\n        layers.append(nn.Sigmoid())\n    elif activation == 'tanh':\n        layers.append(nn.Tanh())\n    elif activation == 'leakyrelu':\n        layers.append(nn.LeakyReLU())\n    elif activation == 'mish': layers.append(nn.Mish())\n    elif activation == 'gelu': layers.append(nn.GELU())\n    elif activation == 'silu': layers.append(nn.SiLU())\n    elif activation == 'softmax':\n        layers.append(nn.Softmax(dim=1))\n    elif activation == 'elu':\n        layers.append(nn.ELU())\n    elif activation == 'selu':\n        layers.append(nn.SELU())\n    elif activation == 'lsoftmax':\n        layers.append(nn.LogSoftmax(dim=1))\n    if dropout > 0.0:\n        layers.append(nn.Dropout(dropout))\n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.767464Z","iopub.execute_input":"2025-10-01T11:42:40.767911Z","iopub.status.idle":"2025-10-01T11:42:40.817246Z","shell.execute_reply.started":"2025-10-01T11:42:40.767887Z","shell.execute_reply":"2025-10-01T11:42:40.816334Z"}},"outputs":[],"execution_count":9},{"id":"27a449c0","cell_type":"code","source":"class Backbone(nn.Module):\n    def __init__(self, backbone=\"efficientnet_b0\", dropout=0.0, freeze=True):\n        super().__init__()\n        self.backbone_name = backbone\n\n        if backbone == \"efficientnet_b0\":\n            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n            self.backbone = models.efficientnet_b0(weights=weights).features\n            feature_dim = 1280\n            self.needs_pooling = True\n\n        elif backbone == \"efficientformer_l1\":\n            self.backbone = timm.create_model(\"efficientformer_l1\", pretrained=True, num_classes=0)\n            feature_dim = 448\n            self.needs_pooling = False\n\n        else:\n            raise ValueError(f\"Backbone {backbone} tidak didukung\")\n\n        if freeze:\n            for param in self.backbone.parameters():\n                param.requires_grad = False\n        else:\n            print(\"param backbone unfreeze\")\n            for param in self.backbone.parameters():\n                param.requires_grad = True\n\n        self.classifier = nn.Sequential(\n            linear_block(feature_dim, 512, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(512, 256, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(256, 128, activation='gelu', dropout=dropout, batch_norm=True),\n            linear_block(128, 5, activation=None)\n        )\n\n    def forward(self, X):\n        X = self.backbone(X)\n        if self.needs_pooling: \n            X = X.mean([2, 3])\n        return self.classifier(X)\n        \nclass PL(LightningModule):\n    def __init__(self, model, class_weights, learning_rate=1e-3) -> None:\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = model\n        self.criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n        self.macroF1 = F1Score(num_classes=5, average='macro', task='multiclass')\n    \n    def forward(self, X):\n        return self.model(X)\n    \n    def _common_step(self, batch, batch_idx):\n        X, labels = batch\n        outputs = self(X) \n        loss = self.criterion(outputs, labels)\n        macrof1 = self.macroF1(outputs, labels)\n        return loss, macrof1\n\n    def training_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_macrof1', macroF1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):\n        loss, macroF1 = self._common_step(batch, batch_idx)\n        self.log('test_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log('test_macrof1', macroF1, on_epoch=True, prog_bar=True, logger=True)\n\n    def configure_optimizers(self):\n        backbone_params = [p for p in self.model.backbone.parameters() if p.requires_grad]\n        head_params = list(self.model.classifier.parameters())\n    \n        optimizer = optim.AdamW([\n            {\"params\": backbone_params, \"lr\": 3e-5},   \n            {\"params\": head_params, \"lr\": self.hparams.learning_rate},  \n        ], weight_decay=1e-4)\n    \n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=5,      \n            T_mult=1,   \n            eta_min=1e-5 \n        )\n\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        \"\"\"\n        Langkah prediksi untuk satu batch data test.\n        \"\"\"\n        images, image_names = batch\n        outputs = self.forward(images)\n        _, predicted_labels = torch.max(outputs, 1)\n        return {\"image_names\": image_names, \"preds\": predicted_labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.820564Z","iopub.execute_input":"2025-10-01T11:42:40.820864Z","iopub.status.idle":"2025-10-01T11:42:40.841099Z","shell.execute_reply.started":"2025-10-01T11:42:40.820844Z","shell.execute_reply":"2025-10-01T11:42:40.840350Z"}},"outputs":[],"execution_count":10},{"id":"2564e101","cell_type":"code","source":"from pytorch_lightning.callbacks import Callback\n\nclass FineTuningCallback(Callback):\n    def __init__(self, unfreeze_schedule, base_backbone_lr=5e-5, head_lr=1e-4, warmup_epochs=10):\n        \"\"\"\n        unfreeze_schedule: dict {epoch: fraction_to_unfreeze}\n            Contoh {1: 0.3, 5: 0.6, 10: 1.0}\n        base_backbone_lr: LR maksimum backbone\n        head_lr: LR classifier head\n        warmup_epochs: jumlah epoch untuk naik linear dari 0 → base_backbone_lr\n        \"\"\"\n        super().__init__()\n        self.unfreeze_schedule = unfreeze_schedule\n        self.base_backbone_lr = base_backbone_lr\n        self.head_lr = head_lr\n        self.warmup_epochs = warmup_epochs\n\n    def on_train_epoch_start(self, trainer, pl_module):\n        current_epoch = trainer.current_epoch\n\n        # Cek apakah ada event unfreeze di epoch ini\n        if current_epoch in self.unfreeze_schedule:\n            fraction = self.unfreeze_schedule[current_epoch]\n            backbone_layers = list(pl_module.model.backbone.children())\n            n_layers = len(backbone_layers)\n            cut_point = int(n_layers * (1 - fraction))\n\n            # Freeze semua dulu\n            for param in pl_module.model.backbone.parameters():\n                param.requires_grad = False\n            # Unfreeze sesuai fraction\n            for layer in backbone_layers[cut_point:]:\n                for param in layer.parameters():\n                    param.requires_grad = True\n\n            print(f\"\\n--- Epoch {current_epoch}: Unfreeze {fraction*100:.0f}% backbone ---\")\n\n        # Hitung LR backbone (linear warmup)\n        progress = min(1.0, (current_epoch + 1) / self.warmup_epochs)\n        backbone_lr = self.base_backbone_lr * progress\n\n        # Update optimizer param groups\n        optimizer = trainer.optimizers[0]\n        defaults = optimizer.defaults\n        param_groups = [\n            {**defaults, \"params\": pl_module.model.backbone.parameters(), \"lr\": backbone_lr},\n            {**defaults, \"params\": pl_module.model.classifier.parameters(), \"lr\": self.head_lr},\n        ]\n        optimizer.param_groups = param_groups\n\n        print(f\"LR backbone={backbone_lr:.2e} (warmup {progress*100:.0f}%), \")\n        print(f\"LR head={self.head_lr:.2e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.842016Z","iopub.execute_input":"2025-10-01T11:42:40.842266Z","iopub.status.idle":"2025-10-01T11:42:40.863139Z","shell.execute_reply.started":"2025-10-01T11:42:40.842248Z","shell.execute_reply":"2025-10-01T11:42:40.862303Z"}},"outputs":[],"execution_count":11},{"id":"dbe4a619-7207-4c4c-9174-0ee67e6a0386","cell_type":"code","source":"import json\nimport yaml\nimport subprocess\nimport shutil\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nKAGGLE_USERNAME = \"dimassp1\"\nDATASET_NAME = \"efficientnet-training-output\"\nDATASET_SLUG = f\"{KAGGLE_USERNAME}/{DATASET_NAME}\"\n\nconfig = {\n    \"architecture\": \"EfficientNet-B0\",\n    \"dropout\": 0.3,\n    \"freeze\": False,\n    \"optimizer\": \"AdamW\",\n    \"optimizer_params\": {\"lr\": 1e-3},\n    \"loss_function\": \"CrossEntropyLoss\",\n    \"metrics\": [\"F1Score_macro\"],\n    \"epochs\": 100,\n    \"batch_size\": bs,\n    \"input_size\": (224, 224),\n    \"num_classes\": 5\n}\n\nOUTPUT_DIR = \"/kaggle/working/output_dataset\"\n\nimport os, shutil, torch, yaml, zipfile\n\ndef save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    best_ckpt_path = checkpoint_callback.best_model_path\n    if best_ckpt_path and os.path.exists(best_ckpt_path):\n        checkpoint_file = os.path.basename(best_ckpt_path)  \n        dst_path = os.path.join(output_dir, checkpoint_file)\n\n        if os.path.abspath(best_ckpt_path) != os.path.abspath(dst_path):\n            shutil.copy(best_ckpt_path, dst_path)\n        else:\n            print(f\"ℹ️ Checkpoint sudah ada di {output_dir}, tidak perlu copy ulang.\")\n\n    else:\n        print(\"⚠️ Best checkpoint belum ada, file .ckpt tidak disalin.\")\n\n    full_state_dict = model.state_dict()\n    backbone_state_dict = {}\n    backbone_keys = [k for k in full_state_dict.keys() if k.startswith(\"features.\")]\n    num_keys_to_save = max(1, int(len(backbone_keys) * backbone_ratio))\n\n    for k in backbone_keys[:num_keys_to_save]:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    head_keys = [k for k in full_state_dict.keys() if k.startswith(\"classifier.\")]\n    for k in head_keys:\n        param = dict(model.named_parameters())[k]\n        if param.requires_grad:\n            backbone_state_dict[k] = full_state_dict[k]\n\n    torch.save(backbone_state_dict, os.path.join(output_dir, \"efficientnet_partial_state_dict.pt\"))\n\n    with open(os.path.join(output_dir, \"config.yaml\"), \"w\") as f:\n        yaml.dump(config, f)\n\n    zip_path = os.path.join(output_dir, \"output_dataset.zip\")\n    files_to_zip = [\n        f for f in [\"config.yaml\", \"efficientnet_partial_state_dict.pt\"] \n        if os.path.exists(os.path.join(output_dir, f))\n    ]\n    if best_ckpt_path:\n        files_to_zip.append(os.path.basename(best_ckpt_path))\n\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for f in files_to_zip:\n            file_path = os.path.join(output_dir, f)\n            zipf.write(file_path, arcname=f)\n\n    print(f\"✅ Semua output sudah di-zip: {zip_path}\")\n    return zip_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.864045Z","iopub.execute_input":"2025-10-01T11:42:40.864329Z","iopub.status.idle":"2025-10-01T11:42:40.885563Z","shell.execute_reply.started":"2025-10-01T11:42:40.864302Z","shell.execute_reply":"2025-10-01T11:42:40.884749Z"}},"outputs":[],"execution_count":12},{"id":"2abb4f79-2be0-4d05-aa65-dcdc7252421b","cell_type":"code","source":"schedule = {\n    2000: 0.3,  \n    1000: 0.6,   \n    0: 1.0   \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.886500Z","iopub.execute_input":"2025-10-01T11:42:40.887098Z","iopub.status.idle":"2025-10-01T11:42:40.904255Z","shell.execute_reply.started":"2025-10-01T11:42:40.887073Z","shell.execute_reply":"2025-10-01T11:42:40.903433Z"}},"outputs":[],"execution_count":13},{"id":"c19ac7d8","cell_type":"code","source":"if torch.cuda.is_available():\n    accelerator_type = 'gpu'\n    devices_to_use = 1\nelse:\n    accelerator_type = 'cpu'\n    devices_to_use = 'auto'\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='train_macrof1',\n    dirpath=OUTPUT_DIR,\n    filename='logikaui_efficientformerl1-{epoch:02d}-{train_macrof1:.4f}',\n    save_top_k=1,\n    mode='max'\n)\nearly_stopping = EarlyStopping(\n    monitor='train_loss',\n    patience=15,\n    mode='min',\n)\nlr_monitor_callback = LearningRateMonitor(logging_interval='epoch')\n\ntrainer1 = pl.Trainer(\n    max_epochs=config[\"epochs\"],\n    callbacks=[checkpoint_callback, early_stopping, lr_monitor_callback],\n    logger=TensorBoardLogger(\"tb_logs\", name=\"efficientnet_exp\"),\n    accelerator=accelerator_type,\n    devices=devices_to_use,\n    log_every_n_steps=10,\n    deterministic=True,\n    # precision=16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.905125Z","iopub.execute_input":"2025-10-01T11:42:40.905400Z","iopub.status.idle":"2025-10-01T11:42:40.988138Z","shell.execute_reply.started":"2025-10-01T11:42:40.905375Z","shell.execute_reply":"2025-10-01T11:42:40.987505Z"}},"outputs":[],"execution_count":14},{"id":"1ad56595","cell_type":"markdown","source":"## Train","metadata":{}},{"id":"c3324805-104f-4284-8da7-7cc954a207bd","cell_type":"code","source":"class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.988913Z","iopub.execute_input":"2025-10-01T11:42:40.989180Z","iopub.status.idle":"2025-10-01T11:42:40.996117Z","shell.execute_reply.started":"2025-10-01T11:42:40.989155Z","shell.execute_reply":"2025-10-01T11:42:40.995364Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([0.0013, 0.0105, 0.0145, 0.0040, 0.0018])"},"metadata":{}}],"execution_count":15},{"id":"9a5c98a3","cell_type":"code","source":"model = PL(Backbone(dropout=0.5, freeze=False, backbone=\"efficientformer_l1\"), class_weights=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:40.997015Z","iopub.execute_input":"2025-10-01T11:42:40.997270Z","iopub.status.idle":"2025-10-01T11:42:41.929026Z","shell.execute_reply.started":"2025-10-01T11:42:40.997252Z","shell.execute_reply":"2025-10-01T11:42:41.928131Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d580a7e843004721a6559bc42fc42579"}},"metadata":{}},{"name":"stdout","text":"param backbone unfreeze\n","output_type":"stream"}],"execution_count":16},{"id":"79ff809c-5385-40eb-b265-373ce7be595f","cell_type":"code","source":"from torch.serialization import add_safe_globals\n\nadd_safe_globals([Backbone, PL])  # ✅ tambahkan kelas custommu\n\ncheckpoint = torch.load(\n    \"/kaggle/input/train-logika/logikaui_efficientformerl1-epoch00-train_macrof10.9443.ckpt\",\n    map_location=\"cpu\",\n    weights_only=False\n)\nmodel.load_state_dict(checkpoint[\"state_dict\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:41.929993Z","iopub.execute_input":"2025-10-01T11:42:41.930368Z","iopub.status.idle":"2025-10-01T11:42:42.854065Z","shell.execute_reply.started":"2025-10-01T11:42:41.930341Z","shell.execute_reply":"2025-10-01T11:42:42.853343Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":17},{"id":"6d142303","cell_type":"code","source":"# trainer1.fit(model, train_loader, val_dataloaders=None, ckpt_path=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:42.854929Z","iopub.execute_input":"2025-10-01T11:42:42.855285Z","iopub.status.idle":"2025-10-01T11:42:42.858875Z","shell.execute_reply.started":"2025-10-01T11:42:42.855265Z","shell.execute_reply":"2025-10-01T11:42:42.858194Z"}},"outputs":[],"execution_count":18},{"id":"5fd6f46c-ce61-4c5f-bb9f-4df989d17759","cell_type":"code","source":"# zip_path = save_pipeline(model, checkpoint_callback, config, output_dir=OUTPUT_DIR, backbone_ratio=0.3)\n# print(\"Zip file:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:42.859784Z","iopub.execute_input":"2025-10-01T11:42:42.860045Z","iopub.status.idle":"2025-10-01T11:42:42.874371Z","shell.execute_reply.started":"2025-10-01T11:42:42.860025Z","shell.execute_reply":"2025-10-01T11:42:42.873491Z"}},"outputs":[],"execution_count":19},{"id":"738ba917","cell_type":"code","source":"if __name__ == \"__main__\":\n    preds = trainer1.predict(model, test_loader, ckpt_path=None)\n    print(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T11:42:42.875299Z","iopub.execute_input":"2025-10-01T11:42:42.875918Z"}},"outputs":[{"name":"stderr","text":"2025-10-01 11:42:44.744876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759318964.928402      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759318964.984365      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"id":"4f001afb","cell_type":"code","source":"predictions = []\nfor batch_result in preds:\n    image_names = batch_result['image_names']\n    preds = batch_result['preds'].cpu().numpy() \n    \n    for name, label in zip(image_names, preds):\n        predictions.append({\n            'id': name,     \n            'style': label  \n        })\npredictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3da01ac3-565b-4a53-90f7-6730ac16ea1a","cell_type":"code","source":"submission_df = pd.DataFrame(predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4a9f8d91-ee0e-4b98-833c-0615ed20cc7d","cell_type":"code","source":"class_mapping = {'balinese': 0, 'batak': 1, 'dayak': 2, 'javanese': 3, 'minangkabau': 4}\nidx_to_class = {v: k for k, v in class_mapping.items()}\nprint(f\"Tipe data kolom 'style': {submission_df['style'].dtype}\")\nsubmission_df['id'] = submission_df['id'].str.split('.').str[0]\n\nprint(f\"Nilai unik di kolom 'style': {submission_df['style'].unique()}\")\nsubmission_df['style'] = submission_df['style'].map(idx_to_class)\nsubmission_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6ced9ca8-ef3c-4aa6-b915-1e4272a0c6fd","cell_type":"code","source":"submission_df.to_csv('submissio1.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"57a07a0a-b589-4fb8-b9f3-f78788195eac","cell_type":"code","source":"\n# Mean & Std ImageNet\nimagenet_mean = np.array([0.485, 0.456, 0.406])\nimagenet_std  = np.array([0.229, 0.224, 0.225])\n\nimages_shown = 0\nmax_images = 444   # jumlah gambar yg ingin ditampilkan\nrows, cols = 5, 6\nper_page = rows * cols  # = 30\n\nfor images, labels in test_loader:\n    for j in range(images.size(0)):\n        if images_shown >= max_images:\n            break\n\n        # Kalau mulai halaman baru (kelipatan 30), bikin figure baru\n        if images_shown % per_page == 0:\n            if images_shown > 0:   # tutup figure lama\n                plt.tight_layout()\n                plt.show()\n            plt.figure(figsize=(15, 10))\n\n        # posisi subplot (1–30 di setiap figure)\n        subplot_idx = (images_shown % per_page) + 1\n        plt.subplot(rows, cols, subplot_idx)\n        plt.axis(\"off\")\n\n        # ambil image (C,H,W) -> (H,W,C)\n        img = images[j].cpu().permute(1, 2, 0).numpy()\n\n        # denormalisasi imagenet\n        img = (img * imagenet_std) + imagenet_mean\n        img = img.clip(0, 1)\n\n        plt.imshow(img)\n\n        # tampilkan label (bisa mapping ke nama kelas kalau perlu)\n        label = submission_df['style'][j] \n        plt.title(label, fontsize=8)\n\n        images_shown += 1\n\n    if images_shown >= max_images:\n        break\n\n# tampilkan figure terakhir kalau belum ditutup\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c0049ef0-3a2b-47c5-a0e6-e13651a15fbf","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7f809574-4175-4c96-b25e-62e55033a5e9","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c360b12b-9915-469a-83ee-337f5b9d143c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a0bba659-b356-407a-ad39-eb6e01833725","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}